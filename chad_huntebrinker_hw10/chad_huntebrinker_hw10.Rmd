---
title: "Chad Huntebrinker's Homework 10"
author: "Chad Huntebrinker"
date: "2024-11-17"
output:
  word_document: default
  html_document: default
---

Problem 9.10 and 9.11
```{r}
#Chad Huntebrinker

library(leaps)
library(readxl)

excel_data <- read_excel("Job_Proficiency_Data.xlsx")

#Problem 9.10a
stem(excel_data$X1)
stem(excel_data$X2)
stem(excel_data$X3)
stem(excel_data$X4)

#Some noteworthy features include:
#1) All tests have max scores that go over 100, but some max scores are 116 while others
#are 140
#2) The distribution of the data for X2 seem to be more on the larger side (greater than
# 110) while the distribution for X1 are on the less side (less than 110)

#Problem 9.10b
pairs(excel_data)
cor(excel_data)
cor(excel_data[,-1])
#It looks like there might be some correlation concerns with Y for X3 and X4
#There also might be some concerns with X3 and X4

#Problem 9.10c
model_1 <- lm(Y~X1 + X2 + X3 + X4, data=excel_data)
sum_of_model_1 <- summary(model_1)
#Y = -124.38182 + 0.29573X1 + 0.04829X2 + 1.30601X3 + 0.51982X4
sum_of_model_1
sum_of_model_1$adj.r.squared
#the adjusted R^2 has a good score (0.9554702) and the p-value for these predictor variables
#seem okay for all except one.  X2 has a p-value of 0.40383, suggesting that it might be
#better to drop X2 from the model

#Problem 9.11a
ma <- regsubsets(Y~., nbest = 4, data=excel_data)
(sma <- summary(ma))
sma$adjr2
order(sma$adjr2, decreasing = TRUE)[1:4]
#(1) [X1, X3, X4] = 0.9560482 
#(2) [X1, X2, X3, X4] = 0.9554702
#(3) [X1, X3] = 0.9269043 
#(4) [X1, X2, X3] = 0.9246779

#9.11b
#There are a couple of other criteria we could look at to narrow down what model we should use.
#First, we could use some of the other measurements to see if a model is a good fit (like AIC, SSEp,
# and PRESSp) to see if they agree.  Another thing we could do is look at the residuals of these models
#to see if they fit the model well.  Finally, we can look at the simplicity of the model.  In general,
#it's better to have a model that has less predictive variables than one that has more.
```


Problem 9.25
```{r}
#Chad Huntebrinker

library(leaps)
library(readxl)

excel_data <- read_excel("SENIC_Data.xlsx")
#Use only rows 57 thru 113 and remove Region and Medical Affiliation
model_data <- excel_data[57:113, ]
model_data <- model_data[, -9]
model_data <- model_data[, -8]
#Note: I believe we should also remove the ID number from the data we use as this shouldn't have
#an impact on the patient's length of stay.  But we'll keep it in as the instructions didn't say
#to remove it.

#Problem 9.25a
for (col_name in names(model_data)) {
  dotchart(model_data[[col_name]], main = paste("Dot Plot of", col_name), xlab = col_name)
}
#Variables that have outliers:
#Number of Beds
#Average daily census
#Number of nurses

#Variables that have spaces in the data:
#Available facilities and services

#Also, ID number is completely linear as patients are assigned them as they are admitted

#Problem 9.25b
pairs(model_data)
cor(model_data)
#Remove ID number and length of stay
cor(model_data[,-2])
#Major concern with linear pairwise associations:
#number of beds and average daily census = 0.99000302
#average daily census and number of nurses 0.90388584
#number of beds and number of nurses = 0.90892888

#Minor concern:
#available facilities and services and number of nurses = 0.7070559
#available facilities and services and number of beds = 0.7644784
#average daily census and available facilities and services = 0.7294165

#Problem 9.25c
model_subsets <- regsubsets(log(Length_of_Stay)~., nbest = 12, data=model_data)
(sum_of_model_subsets <- summary(model_subsets))
sum_of_model_subsets$cp
order(sum_of_model_subsets$cp, decreasing = FALSE)[1:3]
sum_of_model_subsets$which[34,]
sum_of_model_subsets$which[46,]
sum_of_model_subsets$which[47,]
#(1) 4.032107
#(Intercept), ID_Number, Age, Routine_Chest_X-ray, Average_daily_census
5 - 4.032107
#(2) 4.414536
#(Intercept), ID_Number, Age, Routine_Chest_X-ray, Number_of_Beds, Average_daily_census
6 - 4.414536
#(3) 4.951662
#(Intercept), ID_Number, Age, Routine_Culturing_Ratio, Routine_Chest_X-ray, Average_daily_census
6 - 4.951662

#The first model (the one with with the predictor values of Intercept, ID_Number, 
#Age, Routine_Chest_X-ray, Average_daily_census) has the least bias as the Cp score is closest to the
#number of predictor variables it uses.
```

